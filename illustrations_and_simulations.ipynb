{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Illustrations for the Seminar Presentation",
   "id": "1ae2e48b57086da8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1. Plotting Basic ReLU Functions\n",
   "id": "5fe308afdaa21774"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create data points\n",
    "x = np.linspace(0, 12, 1000)\n",
    "data_points = [2, 3, 8]\n",
    "\n",
    "# Define colors for each graph\n",
    "colors = ['b', 'r', 'g']\n",
    "\n",
    "# Create figure with 2 rows (A+ and A-) and 3 columns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "fig.suptitle('ReLU Dictionary Matrix Features')\n",
    "\n",
    "# Plot A+ features\n",
    "for i, dp in enumerate(data_points):\n",
    "    if i == 2:\n",
    "        x_local = np.linspace(0, 12, 1000)\n",
    "    else:\n",
    "        x_local = x\n",
    "\n",
    "    y = np.maximum(x_local - dp, 0)\n",
    "    axes[0, i].plot(x_local, y, colors[i] + '-', label=f'max(x-{dp},0)')\n",
    "    axes[0, i].axvline(x=dp, color='r', linestyle='--', alpha=0.3)\n",
    "    axes[0, i].set_title(f'Positive feature at x={dp}')\n",
    "    axes[0, i].set_ylim(-0.5, 4)\n",
    "    axes[0, i].grid(False)\n",
    "    axes[0, i].legend()\n",
    "    # Plot data points\n",
    "    axes[0, i].plot(data_points, [0]*len(data_points), 'ko')\n",
    "\n",
    "# Plot A- features\n",
    "for i, dp in enumerate(data_points):\n",
    "    y = np.maximum(dp - x, 0)\n",
    "    axes[1, i].plot(x, y, colors[i] + '-', label=f'max({dp}-x,0)')\n",
    "    axes[1, i].axvline(x=dp, color='r', linestyle='--', alpha=0.3)\n",
    "    axes[1, i].set_title(f'A- Feature at x={dp}')\n",
    "    axes[1, i].set_ylim(0, 4)\n",
    "    axes[1, i].grid(False)\n",
    "    axes[1, i].legend()\n",
    "    # Plot data points\n",
    "    axes[1, i].plot(data_points, [0]*len(data_points), 'ko')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "id": "efb57c0bb76311ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2. Plotting Capped Ramp Functions\n",
   "id": "e95c1cb1c77cb3f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definition der aufsteigenden capped ramp function\n",
    "def capped_ramp_plus(x, a1, a2):\n",
    "    return np.piecewise(x,\n",
    "                        [x <= a1, (x > a1) & (x <= a2), x > a2],\n",
    "                        [0, lambda x: x - a1, a2 - a1])\n",
    "\n",
    "# Definition der absteigenden capped ramp function\n",
    "def capped_ramp_minus(x, a1, a2):\n",
    "    return np.piecewise(x,\n",
    "                        [x <= a1, (x > a1) & (x <= a2), x > a2],\n",
    "                        [a2 - a1, lambda x: a2 - x, 0])\n",
    "\n",
    "# Wertebereich für x\n",
    "x = np.linspace(0, 7, 1000)\n",
    "\n",
    "# Breakpoints\n",
    "a1, a2 = 2, 5\n",
    "\n",
    "# Werte für die Funktionen berechnen\n",
    "y_plus = capped_ramp_plus(x, a1, a2)\n",
    "y_minus = capped_ramp_minus(x, a1, a2)\n",
    "\n",
    "# Plot 1: Aufsteigende capped ramp function\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y_plus, label=r'$\\text{Ramp}^+_{x_i,x_i}(x)$', color='blue')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(-1, 4)  # Grenzt den Plot auf eine sinnvolle Höhe ein\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Absteigende capped ramp function\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y_minus, label=r'$\\text{Ramp}^-_{x_i,x_j}(x)$', color='red')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(-1, 4)  # Grenzt den Plot auf eine sinnvolle Höhe ein\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ],
   "id": "d7510cd420457429",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.3. Stock Plots for Breakpoints and Reflections\n",
    "##### This only serves as an illustration. No optimization is performed."
   ],
   "id": "72b88dcb38482af9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3.1. Only data points as break points",
   "id": "2b0991c98daddbda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_values = [0, 2, 3, 8]\n",
    "y_values = [0, 0, 4, 5]\n",
    "\n",
    "colors = ['blue', 'blue', 'blue', 'blue']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, y_values, 'b-', label='Stock Price Trend')\n",
    "plt.scatter(x_values, y_values, color=colors, zorder=5)\n",
    "\n",
    "plt.xlabel('Day', fontsize=12)\n",
    "plt.ylabel('Stock Price', fontsize=12)\n",
    "\n",
    "plt.axhline(y=3, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axhline(y=7, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axvline(x=2, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axvline(x=8, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "\n",
    "plt.xlim(0.1, 8.08)\n",
    "plt.ylim(-0.5, 5.2)\n",
    "\n",
    "plt.title('Stock Price Over Days', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "c78484ab99b7476e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3.2. Including normal reflections",
   "id": "71f67c5d0b7a2b2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_values = [0, 1, 2, 3, 4, 8, 13, 14]\n",
    "y_values = [0, 0, 0, 4, 4.6, 5, 5.3, 6]\n",
    "\n",
    "colors = ['blue', 'green', 'blue', 'blue', 'green', 'blue', 'green', 'green']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, y_values, 'b-', label='Stock Price Trend')\n",
    "plt.scatter(x_values, y_values, color=colors, zorder=5)\n",
    "\n",
    "plt.xlabel('Day', fontsize=12)\n",
    "plt.ylabel('Stock Price', fontsize=12)\n",
    "\n",
    "plt.axhline(y=3, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axhline(y=7, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axvline(x=2, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axvline(x=8, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "\n",
    "plt.xlim(0.1, 14.1)\n",
    "plt.ylim(-0.5, 6.2)\n",
    "\n",
    "plt.title('Stock Price Over Days', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "fffe22568ab680f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3.2. Including double reflections",
   "id": "4da9f43a7639b77b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_values = [0, 1, 2, 3, 4, 7, 8, 13, 14, 15]\n",
    "y_values = [0, 0, 0, 4, 4.6, 5.3, 5, 5.3, 6, 5.7]\n",
    "\n",
    "colors = ['blue', 'green', 'blue', 'blue', 'green', 'red','blue', 'green', 'green', 'grey']\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, y_values, 'b-', label='Stock Price Trend')\n",
    "plt.scatter(x_values, y_values, color=colors, zorder=5)\n",
    "\n",
    "plt.xlabel('Day', fontsize=12)\n",
    "plt.ylabel('Stock Price', fontsize=12)\n",
    "\n",
    "plt.axhline(y=3, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axhline(y=7, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axvline(x=2, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "plt.axvline(x=8, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "\n",
    "plt.xlim(0.1, 15.1)\n",
    "plt.ylim(-0.5, 6.2)\n",
    "\n",
    "plt.title('Stock Price Over Days', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "3d44a7fe492caa35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2.Simulations",
   "id": "ccafcae9dc87d96c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 CRH\n",
    "##### Simulating RGA and plotting alignment for different layers. The goal was not a perfect reflection of the CRH but rather to get an intuition for how the layers behave."
   ],
   "id": "44d6883b6f6013eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Simulation to validate the Representation-Gradient Alignment (RGA) hypothesis from Ziyin et al. (2024).\n",
    "\n",
    "The simulation examines how representations in different layers of a neural network align with their\n",
    "gradients during training. It uses:\n",
    "\n",
    "Network Architecture:\n",
    "- 6-layer feedforward network\n",
    "- Input dimension: 1\n",
    "- Hidden dimension: 4\n",
    "- Output dimension: 1\n",
    "\n",
    "Training Setup:\n",
    "- Synthetic dataset: Sine wave with Gaussian noise\n",
    "- 13000 epochs\n",
    "- Adam optimizer with learning rate 0.01\n",
    "- Weight decay (gamma): 1e-5\n",
    "- MSE loss function\n",
    "\n",
    "Measurement:\n",
    "For each layer, computes alignment between:\n",
    "- H: Layer activations\n",
    "- G: Gradients of these activations\n",
    "Alignment strength is measured through normalized correlation of covariance matrices.\n",
    "\n",
    "The results support the paper's prediction that:\n",
    "1. Representations align with their gradients during training\n",
    "2. Deeper layers show stronger alignment\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function for calculating the alignments\n",
    "def compute_alignment(H, G):\n",
    "    # Normalizing\n",
    "    H = H / torch.norm(H, dim=1, keepdim=True)\n",
    "    G = G / torch.norm(G, dim=1, keepdim=True)\n",
    "\n",
    "    # Calc. Covariance\n",
    "    H_cov = torch.mm(H.t(), H) / H.size(0)\n",
    "    G_cov = torch.mm(G.t(), G) / G.size(0)\n",
    "\n",
    "    # Calc. Alignment\n",
    "    numerator = torch.sum(H_cov * G_cov)\n",
    "    denominator = torch.sqrt(torch.sum(H_cov * H_cov) * torch.sum(G_cov * G_cov))\n",
    "\n",
    "    return (numerator / (denominator + 1e-8)).item()\n",
    "\n",
    "\n",
    "# Implement 6 hidden layers\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = []\n",
    "        x_current = x\n",
    "        for layer in self.layers:\n",
    "            x_current = layer(x_current)\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x_current.retain_grad()\n",
    "                activations.append(x_current)\n",
    "        return x_current, activations\n",
    "\n",
    "\n",
    "# Set trainings parameter\n",
    "input_dim = 1\n",
    "hidden_dim = 4\n",
    "output_dim = 1\n",
    "epochs = 13000\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "gamma = 1e-5\n",
    "\n",
    "# Generate data\n",
    "torch.manual_seed(42)\n",
    "N = 1000\n",
    "X = torch.linspace(-10, 10, N).unsqueeze(1)\n",
    "y = torch.sin(X) + 0.1 * torch.randn_like(X)\n",
    "\n",
    "# Modell, Loss and Optimizer\n",
    "model = SimpleNet(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=gamma)  # Kleinere Regularisierung\n",
    "\n",
    "# Save correlations\n",
    "correlations = {layer: [] for layer in range(6)}  # 6 versteckte Schichten\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs, activations = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Calculate alignments for all layers\n",
    "    for i, activation in enumerate(activations):\n",
    "        if activation.grad is not None:\n",
    "            H = activation\n",
    "            G = -activation.grad\n",
    "            correlation = compute_alignment(H, G)\n",
    "            correlations[i].append(correlation)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for layer, corr_values in correlations.items():\n",
    "    if layer == 0:\n",
    "        plt.plot(range(len(corr_values)), corr_values, label=f'Hidden Layer {layer + 1}', color='blue')\n",
    "    elif layer == 2:\n",
    "        plt.plot(range(len(corr_values)), corr_values, label=f'Hidden Layer {layer + 1}', color='black')\n",
    "    elif layer == 4:\n",
    "        plt.plot(range(len(corr_values)), corr_values, label=f'Hidden Layer {layer + 1}', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Alignment by matrix correlation')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "3674641e6d6f4c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Checking the time the LASSO Model takes for different input dat set sizes\n",
    "#### Important:\n",
    "##### The code is not fully correct regarding what exactly the dictionaries matrices look like. My goal is just to illustrate the different growth rates of feature numbers.\n",
    "\n"
   ],
   "id": "916169ab167c5768"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Compares LASSO solving times for dictionary matrices from different neural architectures:\n",
    "\n",
    "1. Exponential Dictionary (build_exponential_dictionary):\n",
    "   - Corresponds to absolute value/leaky ReLU networks\n",
    "   - Growth rate: O(N^(L-1) * 2^L * L!)\n",
    "   - Implements basic reflection features\n",
    "\n",
    "2. Polynomial Dictionary (build_deep_narrow_relu_dictionary):\n",
    "   - Corresponds to deep narrow ReLU networks\n",
    "   - Growth rate: O(N^2)\n",
    "   - Implements ramp features for L=2 and capped ramps for L=3\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "import time\n",
    "import random\n",
    "# Create example dictionary\n",
    "def build_exponential_dictionary(x, L=3):\n",
    "    # Sort input points\n",
    "    x_sorted = np.sort(x)\n",
    "    N = len(x_sorted)\n",
    "\n",
    "    def base_layer_2(x_sorted):\n",
    "        # Build basic L=2 ramp features (N, 2N)\n",
    "        A_plus = np.zeros((N, N), dtype=np.float32)\n",
    "        A_minus = np.zeros((N, N), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                diff = x[i] - x_sorted[j]\n",
    "                A_plus[i, j] = max(0.0, diff)\n",
    "                A_minus[i, j] = max(0.0, -diff)\n",
    "        return np.hstack([A_plus, A_minus])\n",
    "\n",
    "    A_current = base_layer_2(x_sorted)\n",
    "\n",
    "    def expand_abs_val(A_prev):\n",
    "        # Add reflection features for L>=3\n",
    "        N, M = A_prev.shape\n",
    "        feats = []\n",
    "        for m in range(M):\n",
    "            for j in range(N):\n",
    "                feats.append(np.abs(A_prev[:, m] - x_sorted[j]))\n",
    "                feats.append(np.maximum(0.0, 0.1*(A_prev[:, m] - x_sorted[j])))\n",
    "        return np.column_stack(feats)\n",
    "\n",
    "    # Expand dictionary for each additional layer\n",
    "    for layer_idx in range(3, L+1):\n",
    "        A_next = expand_abs_val(A_current)\n",
    "        A_current = np.hstack([A_current, A_next])\n",
    "\n",
    "    return A_current\n",
    "\n",
    "# Build example dictionary for ReLU\n",
    "def build_deep_narrow_relu_dictionary(x, L=2):\n",
    "    N = len(x)\n",
    "    x_sorted = np.sort(x)\n",
    "\n",
    "    def base_relu_2(x_sorted):\n",
    "        A_plus = np.zeros((N, N), dtype=np.float32)\n",
    "        A_minus = np.zeros((N, N), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                diff = x[i] - x_sorted[j]\n",
    "                A_plus[i, j] = max(0.0, diff)\n",
    "                A_minus[i, j] = max(0.0, -diff)\n",
    "        return np.hstack([A_plus, A_minus])\n",
    "\n",
    "    A_current = base_relu_2(x_sorted)\n",
    "\n",
    "    if L >= 3:\n",
    "        # Implement capped ramps\n",
    "        feats = []\n",
    "        N, M = A_current.shape\n",
    "        for m in range(M):\n",
    "            for j in range(N):\n",
    "                feats.append(np.maximum(0.0, A_current[:, m] - x_sorted[j]))\n",
    "        A_current = np.hstack([A_current, np.column_stack(feats)])\n",
    "\n",
    "    return A_current\n",
    "\n",
    "def run_experiment(n_values, L=3, alpha=0.1, dictionary_type=\"exponential\"):\n",
    "    # Build dictionary and measure LASSO solving time for each n\n",
    "    results = {}\n",
    "    for n in n_values:\n",
    "        x = 10.0 * np.random.rand(n)\n",
    "        A = build_exponential_dictionary(x, L=L) if dictionary_type == \"exponential\" else build_deep_narrow_relu_dictionary(x, L=L)\n",
    "        y = np.random.randn(n)\n",
    "\n",
    "        start = time.time()\n",
    "        model = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n",
    "        model.fit(A, y)\n",
    "        runtime = time.time() - start\n",
    "\n",
    "        results[n] = (runtime, A.shape)\n",
    "        print(f\"{dictionary_type}: L={L}, n={n}, shape={A.shape}, time={runtime:.4f}s\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Compare solving times for both dictionary types\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    random_n_values = sorted(random.sample(range(3, 35), 30))\n",
    "    L = 3\n",
    "\n",
    "    exp_results = run_experiment(random_n_values, L=L, dictionary_type=\"exponential\")\n",
    "    poly_results = run_experiment(random_n_values, L=L, dictionary_type=\"polynomial\")\n",
    "\n",
    "    # Plot results with median smoothing\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for results, label, marker, color in [(exp_results, 'Exponential', 'o', 'r'),\n",
    "                                        (poly_results, 'Polynomial', 's', 'b')]:\n",
    "        x_vals = list(results.keys())\n",
    "        y_vals = [results[n][0] for n in x_vals]\n",
    "        y_smoothed = [median(y_vals[max(0, i-9):i+1]) for i in range(len(y_vals))]\n",
    "        plt.plot(x_vals, y_smoothed, marker=marker, color=color,\n",
    "                label=f'{label} Dictionary')\n",
    "\n",
    "    plt.title(f\"Lasso Runtime\")\n",
    "    plt.xlabel(\"Number of Data Points (N)\")\n",
    "    plt.ylabel(\"Smoothed Time to Solve (seconds)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#run main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ],
   "id": "c08f883590ed30c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
